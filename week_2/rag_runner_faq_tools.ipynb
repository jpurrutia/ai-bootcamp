{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c503381d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m openai_client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assumes OPENAI_API_KEY is set in environment\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    135\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI()  # Assumes OPENAI_API_KEY is set in environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a42b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import AppendableIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbaaab",
   "metadata": {},
   "source": [
    "## Setup and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59898b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490bf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ab456fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x12bbb7830>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd1afc3",
   "metadata": {},
   "source": [
    "## Agentic RAG\n",
    "\n",
    "The biggest difference between traditional RAG (fixed process + rigid) and Agentic RAG is that we let the LLM decide if it needs to invoke the tool or not. We achieve this by using function calling capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c35e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "954cbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e91385f",
   "metadata": {},
   "source": [
    "### Library Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f36fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.llm import OpenAIClient\n",
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.chat.runners import OpenAIResponsesRunner\n",
    "from toyaikit.chat.runners import DisplayingRunnerCallback\n",
    "from toyaikit.tools import Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479251f",
   "metadata": {},
   "source": [
    "### Processing Function Calls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b844c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_tools = Tools()\n",
    "agent_tools.add_tool(search, search_tool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c26156a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "If you want to look up the answer, explain why before making the call\n",
    "\"\"\".strip()\n",
    "\n",
    "question = \"I just discovered the course. Can I still join it?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caea2ef",
   "metadata": {},
   "source": [
    "LLMs are STATELESS, so we need to include conversation history\n",
    "\n",
    "send back entire conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f64ef053",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_interface = IPythonChatInterface()\n",
    "\n",
    "runner = OpenAIResponsesRunner(\n",
    "    tools=agent_tools,\n",
    "    developer_prompt=instructions,\n",
    "    chat_interface=chat_interface,\n",
    "    llm_client=openai_client\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0f05c",
   "metadata": {},
   "source": [
    "#### Running the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "059fea4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'send_request'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m callback = DisplayingRunnerCallback(chat_interface)\n\u001b[32m      3\u001b[39m question = \u001b[33m'\u001b[39m\u001b[33mhow do I install kafka\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m loop_result = \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/ai-bootcamp/.venv/lib/python3.12/site-packages/toyaikit/chat/runners.py:133\u001b[39m, in \u001b[36mOpenAIResponsesRunner.loop\u001b[39m\u001b[34m(self, prompt, previous_messages, callback)\u001b[39m\n\u001b[32m    130\u001b[39m total_output_tokens = \u001b[32m0\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_request\u001b[49m(\n\u001b[32m    134\u001b[39m         chat_messages=chat_messages,\n\u001b[32m    135\u001b[39m         tools=\u001b[38;5;28mself\u001b[39m.tools,\n\u001b[32m    136\u001b[39m     )\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response, \u001b[33m\"\u001b[39m\u001b[33musage\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m response.usage:\n\u001b[32m    139\u001b[39m         total_input_tokens += response.usage.input_tokens\n",
      "\u001b[31mAttributeError\u001b[39m: 'OpenAI' object has no attribute 'send_request'"
     ]
    }
   ],
   "source": [
    "callback = DisplayingRunnerCallback(chat_interface)\n",
    "\n",
    "question = 'how do I install kafka'\n",
    "loop_result = runner.loop(prompt=question, callback=callback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee763d0",
   "metadata": {},
   "source": [
    "Now we are ready to send the results back to the model.\n",
    "\n",
    "invoke API with function call and function call results w/ previous conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc4b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f177183",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fbce4",
   "metadata": {},
   "source": [
    "### Adding Explanations\n",
    "\n",
    "make agent explain its decision-making process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89830b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46971431",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99966484",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": instrunctions},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-40-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee35741",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.output[0].content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c674fe85",
   "metadata": {},
   "source": [
    "The second part contains the function call details.\n",
    "\n",
    "Making these calls manually be executing the notebook cells is not convenient so let's write some code for automating it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6871d",
   "metadata": {},
   "source": [
    "## Agentic Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1f7c9",
   "metadata": {},
   "source": [
    "create more flexible function for handling different types of calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb63a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7acf76b",
   "metadata": {},
   "source": [
    "now the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfad375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac729f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
