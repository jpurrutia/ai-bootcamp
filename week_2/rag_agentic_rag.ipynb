{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c503381d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m openai_client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    135\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a42b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import AppendableIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbaaab",
   "metadata": {},
   "source": [
    "## Setup and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59898b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490bf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab456fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x125a5ac30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd1afc3",
   "metadata": {},
   "source": [
    "## Agentic RAG\n",
    "\n",
    "The biggest difference between traditional RAG (fixed process + rigid) and Agentic RAG is that we let the LLM decide if it needs to invoke the tool or not. We achieve this by using function calling capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c35e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5068a6",
   "metadata": {},
   "source": [
    "### Function Calling\n",
    "the reason we call llms \"agents\". With it, they can invoke any arbitrary function in order to achieve the given goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4443f611",
   "metadata": {},
   "source": [
    "make the LLM use our search function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c44a2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0d54f2",
   "metadata": {},
   "source": [
    "#### List of tools for function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c26156a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"query\":\"Can I still join if I just discovered the course?\"}', call_id='call_j9YlRYgtCde2U4WWfGXwEeSs', name='search', type='function_call', id='fc_071fa133e9ec96380068f255c7d73c819898b666e0ce2574e6', status='completed')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "question = \"I just discovered the course. Can I still join?\"\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": instructions},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "response.output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479251f",
   "metadata": {},
   "source": [
    "### Processing Function Calls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b844c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(query=\"join course late\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caea2ef",
   "metadata": {},
   "source": [
    "LLMs are STATELESS, so we need to include conversation history\n",
    "\n",
    "send back entire conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ef053",
   "metadata": {},
   "outputs": [],
   "source": [
    "call = response.output[0]\n",
    "chat_messages.append(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0f05c",
   "metadata": {},
   "source": [
    "Invoke the function, and also save the function call results in chat_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059fea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(query=\"join course late\")\n",
    "search_results_json = json.dumps(search_results)\n",
    "\n",
    "call_output = {\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": call.call_id,\n",
    "    \"output\": search_results_json,\n",
    "}\n",
    "\n",
    "chat_messages.append(call_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee763d0",
   "metadata": {},
   "source": [
    "Now we are ready to send the results back to the model.\n",
    "\n",
    "invoke API with function call and function call results w/ previous conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc4b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f177183",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fbce4",
   "metadata": {},
   "source": [
    "### Adding Explanations\n",
    "\n",
    "make agent explain its decision-making process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89830b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "If you want to look up the answer, explain why before making the call\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46971431",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99966484",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "question = \"I just discovered the course. Can I still join it?\"\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": instructions},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-40-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee35741",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.output[0].content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c674fe85",
   "metadata": {},
   "source": [
    "The second part contains the function call details.\n",
    "\n",
    "Making these calls manually be executing the notebook cells is not convenient so let's write some code for automating it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6871d",
   "metadata": {},
   "source": [
    "## Agentic Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1f7c9",
   "metadata": {},
   "source": [
    "create more flexible function for handling different types of calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_call(call):\n",
    "    f_name = call.name\n",
    "    arguments = json.loads(call.argument)\n",
    "\n",
    "    if f_name == \"search\":\n",
    "        results = search(**arguments)\n",
    "\n",
    "    # you can add more functions HERE\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown function {f_name}\")\n",
    "    \n",
    "    json_results = json.dumps(results)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": call.call_id,\n",
    "        \"output\": json_results,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7acf76b",
   "metadata": {},
   "source": [
    "now the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfad375",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I just discovered the course. can I still join it?\"\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": instructions},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "while True:\n",
    "    response = openai_client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=chat_messages,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    has_function_calls = False\n",
    "\n",
    "    # add response to chat history for LLM's memory\n",
    "    chat_messages.extend(response.output)\n",
    "\n",
    "    for entry in response.output:\n",
    "        if entry.type == \"funtion_call\":\n",
    "            print(\"Function call:\")\n",
    "            print(entry)\n",
    "            result = make_call(entry)\n",
    "            print('   ', 'Output:')\n",
    "            print('   ', result['output'])\n",
    "            chat_messages.append(result)\n",
    "            has_function_calls = True\n",
    "            print()\n",
    "        \n",
    "        elif entry.type == \"message\":\n",
    "            print(\"Assistant:\")\n",
    "            print(entry.content[0].text)\n",
    "            print()\n",
    "\n",
    "        if not has_function_calls:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac729f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
