{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df17f18d",
   "metadata": {},
   "outputs": [],
   "source": "# YouTube Transcript Processing with LLMs\n\n## Install Dependencies\n\n!uv add youtube-transcript-api"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125235ea",
   "metadata": {},
   "outputs": [],
   "source": "## Import Libraries\n\nimport re\nfrom openai import OpenAI\nimport requests\nimport json\nfrom minsearch import Index, VectorSearch\nimport pickle \nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom typing import Any, Dict, List, Optional\n\nclient = OpenAI()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83000763",
   "metadata": {},
   "outputs": [],
   "source": "## Load Pre-downloaded YouTube Transcript\n\nvideo_id = 'ph1PxZIkz1o'\n\n# Load the cached transcript (pre-fetched to avoid API calls)\nwith open(f'{video_id}.bin', 'rb') as f_in:\n    transcript = pickle.load(f_in)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211824b",
   "metadata": {},
   "outputs": [],
   "source": "## Format Transcript as Subtitles\n\ndef format_timestamp(seconds: float) -> str:\n    \"\"\"Convert seconds to H:MM:SS if > 1 hour else MM:SS\"\"\"\n    total_seconds =  int(seconds)\n    hours, remainder = divmod(total_seconds, 3600)\n    minutes, secs = divmod(remainder, 60)\n\n    if hours > 0:\n        return f\"{hours}:{minutes:02}:{secs:02}\"\n    else:\n        return f\"{minutes}:{secs:02}\"\n    \ndef make_subtitles(transcript) -> str:\n    \"\"\"Convert transcript to timestamped text format\"\"\"\n    lines = []\n\n    for entry in transcript:\n        ts = format_timestamp(entry.start)\n        text = entry.text.replace('\\n', ' ')\n        lines.append(ts + ' ' + text)\n    \n    return '\\n'.join(lines)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54122633",
   "metadata": {},
   "outputs": [],
   "source": "# Preview the formatted subtitles\nsubtitles = make_subtitles(transcript)\nprint(subtitles[:500])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093040ee",
   "metadata": {},
   "outputs": [],
   "source": "## Define Instructions for Summarization\n\ninstructions = \"\"\"\nSummarize the transcript and describe the main purpose of the video\nand the main ideas. \n\nAlso output chapters with time. Use usual sentence case, not Title Case for the chapter.\n\nOutput format: \n\n<OUTPUT>\nSummary\n\ntimestamp chapter \ntimestamp chapter\n...\ntimestamp chapter\n</OUTPUT>\n\"\"\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b941c",
   "metadata": {},
   "outputs": [],
   "source": "## Helper Function for LLM Calls\n\ndef llm(\n    user_prompt: str,\n    *,\n    client: OpenAI,\n    instructions: Optional[str] = None,\n    model: str = \"gpt-4o-mini\",\n) -> str:\n    \"\"\"Call the OpenAI Responses API with optional system instructions\"\"\"\n    messages = []\n    if instructions:\n        messages.append({\"role\": \"system\", \"content\": instructions})\n    messages.append({\"role\": \"user\", \"content\": user_prompt})\n\n    resp = client.responses.create(model=model, input=messages)\n    return resp.output_text"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfc775",
   "metadata": {},
   "outputs": [],
   "source": "## Generate Summary (Unstructured Output)\n\nanswer = llm(subtitles, client=client, instructions=instructions)\nprint(answer)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ecf86",
   "metadata": {},
   "outputs": [],
   "source": "# Helper to strip outer XML tags\ndef strip_matching_outer_html_tags(text: str) -> str:\n    match = re.match(r\"^\\s*<(\\w+)[^>]*>\\s*(.*?)\\s*</\\1>\\s*$\", text, re.DOTALL)\n    if match:\n        return match.group(2).strip()\n    return text.strip()\n\nanswer = strip_matching_outer_html_tags(answer)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d6b32",
   "metadata": {},
   "outputs": [],
   "source": "## Define Pydantic Models for Structured Outputs\n\nfrom pydantic import BaseModel\n\nclass Chapter(BaseModel):\n    timestamp: str\n    title: str\n\nclass YTSummaryResponse(BaseModel):\n    summary: str\n    chapters: list[Chapter]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167daa6",
   "metadata": {},
   "outputs": [],
   "source": "## Generate Structured Summary with Pydantic\n\ninstructions = \"\"\"\nSummarize the transcript and describe the main purpose of the video\nand the main ideas. \n\nAlso output chapters with time. Use usual sentence case, not Title Case for the chapter.\n\nMore chapters is better than fewer chapters. Have a chapter at least every 3-5 minutes\n\"\"\".strip()\n\nmessages = [\n    {\"role\": \"system\", \"content\": instructions}, \n    {\"role\": \"user\", \"content\": subtitles}\n]\n\nresponse = client.responses.parse(\n    model='gpt-4o-mini',\n    input=messages,\n    text_format=YTSummaryResponse\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd78769",
   "metadata": {},
   "outputs": [],
   "source": "## Display the Structured Results\n\nsummary = response.output[0].content[0].parsed\n\nprint(summary.summary)\nprint()\nfor c in summary.chapters:\n    print(c.timestamp, c.title)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce716270",
   "metadata": {},
   "outputs": [],
   "source": "## Create Reusable Structured LLM Function\n\ndef llm_structured(instructions, user_prompt, output_format, client, model=\"gpt-4o-mini\"):\n    \"\"\"Call OpenAI with structured Pydantic output\"\"\"\n    messages = [\n        {\"role\": \"system\", \"content\": instructions},\n        {\"role\": \"user\", \"content\": user_prompt}\n    ]\n\n    response = client.responses.parse(\n        model=model,\n        input=messages,\n        text_format=output_format\n    )\n\n    return response.output[0].content[0].parsed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b57374",
   "metadata": {},
   "outputs": [],
   "source": "# Use the helper function\nsummary = llm_structured(\n    instructions=instructions,\n    user_prompt=subtitles,\n    client=client,\n    output_format=YTSummaryResponse\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c2c7f",
   "metadata": {},
   "outputs": [],
   "source": "# View the structured result\nsummary"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}