{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df17f18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[37m⠼\u001b[0m \u001b[2mjupyter-server-terminals==0.5.3                                               \u001b[0m\u001b[2mResolved \u001b[1m156 packages\u001b[0m \u001b[2min 4.52s\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m     0 B/473.68 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 2.68 KiB/473.68 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 18.68 KiB/473.68 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 34.68 KiB/473.68 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 50.68 KiB/473.68 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 62.02 KiB/473.68 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 78.02 KiB/473.68 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 94.02 KiB/473.68 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 110.02 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 125.05 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 141.05 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 157.05 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 173.05 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 189.05 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 205.05 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------------\u001b[0m\u001b[0m 221.05 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)2m--------------\u001b[0m\u001b[0m 237.05 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)[2m-------------\u001b[0m\u001b[0m 253.05 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\u001b[2m------------\u001b[0m\u001b[0m 269.05 KiB/473.68 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 189ms\u001b[0m\u001b[0m                                                  \u001b[1A\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 69ms\u001b[0m\u001b[0mpi==1.2.2                        \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1myoutube-transcript-api\u001b[0m\u001b[2m==1.2.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "125235ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json\n",
    "from minsearch import Index, VectorSearch\n",
    "import pickle \n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3aefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/alexeygrigorev/ai-bootcamp-codespace/raw/refs/heads/main/week1/ph1PxZIkz1o.bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83000763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "video_id = 'ph1PxZIkz1o'\n",
    "\n",
    "#ytt_api = YouTubeTranscriptApi()\n",
    "#transcript = ytt_api.fetch(video_id)\n",
    "\n",
    "with open(f'{video_id}.bin', 'rb') as f_in:\n",
    "    transcript = pickle.load(f_in)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23704cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1407"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5211824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timestamp(seconds: float) -> str:\n",
    "    \"\"\" Convert seconds to H:MM:SS if > 1 hour else MM:SS \"\"\"\n",
    "    total_seconds =  int(seconds)\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, secs = divmod(remainder, 60)\n",
    "\n",
    "    if hours > 0:\n",
    "        return f\"{hours}:{minutes:02}:{secs:02}\"\n",
    "    else:\n",
    "        return f\"{minutes}:{secs:02}\"\n",
    "    \n",
    "def make_subtitles(transcript) -> str:\n",
    "    lines = []\n",
    "\n",
    "    for entry in transcript:\n",
    "        ts = format_timestamp(entry.start)\n",
    "        text = entry.text.replace('\\n', ' ')\n",
    "        lines.append(ts + ' ' + text)\n",
    "    \n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "subtitles = make_subtitles(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54122633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00 So hi everyone. Uh today we are going to\n",
      "0:02 talk about our upcoming course. The\n",
      "0:05 upcoming course is called machine\n",
      "0:06 learning zoom camp. And um this is\n",
      "0:10 already I put the link in the\n",
      "0:12 description. So if you're watching um\n",
      "0:14 this video in recording or you're\n",
      "0:17 watching it live, you go here in the\n",
      "0:19 description after under this video and\n",
      "0:21 then you see a link course. uh click on\n",
      "0:25 that link and this bring you will bring\n",
      "0:27 you to\n",
      "0:29 this website this GitHub\n"
     ]
    }
   ],
   "source": [
    "print(subtitles[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "093040ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "Summarize the transcript and describe the main purpose of the video\n",
    "and the main ideas. \n",
    "\n",
    "Also output chapters with time. Use usual sentence case, not Title Case for the chapter.\n",
    "\n",
    "Output format: \n",
    "\n",
    "<OUTPUT>\n",
    "Summary\n",
    "\n",
    "timestamp chapter \n",
    "timestamp chapter\n",
    "...\n",
    "timestamp chapter\n",
    "</OUTPUT>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35b941c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm\u001b[39m(\n\u001b[32m      2\u001b[39m     user_prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m      3\u001b[39m     *,\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     client: \u001b[43mOpenAI\u001b[49m,\n\u001b[32m      5\u001b[39m     instructions: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m      6\u001b[39m     model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      8\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m    Call the OpenAI Responses API with optional system instructions and return text.\u001b[39;00m\n\u001b[32m     10\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m \u001b[33;03m        The response text (assistant output) as a string.\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     21\u001b[39m     messages = []\n",
      "\u001b[31mNameError\u001b[39m: name 'OpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "def llm(\n",
    "    user_prompt: str,\n",
    "    *,\n",
    "    client: OpenAI,\n",
    "    instructions: Optional[str] = None,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Call the OpenAI Responses API with optional system instructions and return text.\n",
    "\n",
    "    Args:\n",
    "        user_prompt: The fully-assembled prompt to send as the user message.\n",
    "        client: An initialized `OpenAI()` client.\n",
    "        instructions: Optional system message to steer behavior (e.g., \"answer only\n",
    "            from context; say 'don't know' otherwise\").\n",
    "        model: OpenAI model name.\n",
    "\n",
    "    Returns:\n",
    "        The response text (assistant output) as a string.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if instructions:\n",
    "        messages.append({\"role\": \"system\", \"content\": instructions})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    resp = client.responses.create(model=model, input=messages)\n",
    "    return resp.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dbfc775",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m answer = \u001b[43mllm\u001b[49m(subtitles, client=client, instructions=instructions)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "answer = llm(subtitles, client=client, instructions=instructions)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ecf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_matching_outer_html_tags(text: str) -> str:\n",
    "    match = re.match(r\"^\\s*<(\\w+)[^>]*>\\s*(.*?)\\s*</\\1>\\s*$\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(2).strip()\n",
    "    return text.strip()\n",
    "\n",
    "answer = strip_matching_outer_html_tags(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a80d6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Chapter(BaseModel):\n",
    "    timestamp: str\n",
    "    title: str\n",
    "\n",
    "class YTSummaryResponse(BaseModel):\n",
    "    summary: str\n",
    "    chapters: list[Chapter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8167daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "Summarize the transcript and describe the main purpose of the video\n",
    "and the main ideas. \n",
    "\n",
    "Also output chapters with time. Use usual sentence case, not Title Case for the chapter.\n",
    "\n",
    "More chapters is better than fewer chapters. Have a chapter at least every 3-5 minutes\n",
    "\"\"\".strip()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": instructions}, \n",
    "    {\"role\": \"user\", \"content\": subtitles}\n",
    "]\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model='gpt-4o-mini',\n",
    "    input=messages,\n",
    "    text_format=YTSummaryResponse\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cd78769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video discusses an upcoming course titled \"Machine Learning Zoom Camp.\" The course aims to provide a structured learning path for individuals interested in machine learning engineering. It covers various topics including fundamental machine learning concepts, deployment techniques, and some computer vision basics. Participants can expect to gain relevant skills that enhance their job marketability as they learn to handle real-world ML engineering tasks. The session also includes a Q&A segment addressing prerequisites, course structure, and expected outcomes for participants.\n",
      "\n",
      "0:00 Introduction to the course\n",
      "2:34 Course content and updates\n",
      "5:30 Job placement and prerequisites\n",
      "10:14 Using programming and command line\n",
      "15:38 Mathematical prerequisites explained\n",
      "19:31 Course format and certificate details\n",
      "25:23 Deadlines and project requirements\n",
      "32:31 Interactivity and learning management\n",
      "36:00 Course expectations and job readiness\n",
      "40:30 Final thoughts and Q&A follow-up\n"
     ]
    }
   ],
   "source": [
    "summary = response.output[0].content[0].parsed\n",
    "\n",
    "print(summary.summary)\n",
    "print()\n",
    "for c in summary.chapters:\n",
    "    print(c.timestamp, c.title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce716270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_structured(instructions, user_prompt, output_format, client, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model=model,\n",
    "        input=messages,\n",
    "        text_format=output_format\n",
    "    )\n",
    "\n",
    "    return response.output[0].content[0].parsed\n",
    "    # or return response.output_parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01b57374",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YTSummaryResponse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m summary = llm_structured(\n\u001b[32m      2\u001b[39m     instructions=instructions,\n\u001b[32m      3\u001b[39m     user_prompt=subtitles,\n\u001b[32m      4\u001b[39m     client=client,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     output_format=\u001b[43mYTSummaryResponse\u001b[49m\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'YTSummaryResponse' is not defined"
     ]
    }
   ],
   "source": [
    "summary = llm_structured(\n",
    "    instructions=instructions,\n",
    "    user_prompt=subtitles,\n",
    "    client=client,\n",
    "    output_format=YTSummaryResponse\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "984c2c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YTSummaryResponse(summary='The video is an overview and Q&A session regarding the upcoming \"Machine Learning Zoom Camp\" course, scheduled to start on September 15. The instructor discusses key aspects of the course, including its structure, prerequisites, and expected outcomes for participants. The course aims to teach foundational machine learning skills with a strong focus on engineering aspects, particularly deployment. Questions are answered regarding job prospects, prerequisites, and the depth of coverage for various topics like deep learning and computer vision. Overall, it serves as an informative session for prospective students to understand the course details and content better.', chapters=[Chapter(timestamp='0:00', title='Introduction to the upcoming course'), Chapter(timestamp='2:30', title='Course structure and updates'), Chapter(timestamp='5:10', title='Job placement prospects after the course'), Chapter(timestamp='8:10', title='Prerequisites for the course'), Chapter(timestamp='11:50', title='Focus on machine learning vs. engineering'), Chapter(timestamp='14:30', title='Recommended companion book for the course'), Chapter(timestamp='17:40', title='Technical requirements and tools'), Chapter(timestamp='22:00', title='Career path and roles after completing the course'), Chapter(timestamp='26:20', title='Projects and certificates'), Chapter(timestamp='30:20', title='Learning environment and interaction'), Chapter(timestamp='34:00', title='Course commitment and deadlines'), Chapter(timestamp='36:40', title='Student engagement and community'), Chapter(timestamp='40:30', title='Final thoughts and signup information')])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "752f9e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [9, 10, 11, 12, 13, 14, 15, 16, 17]]\n"
     ]
    }
   ],
   "source": [
    "def sliding_window(seq, size, step):\n",
    "    \"\"\"Create overlapping chunks using sliding window approach.\"\"\"\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        batch = seq[i:i+size]\n",
    "        result.append(batch)\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example:\n",
    "print(sliding_window(list(range(18)), 10, 3))\n",
    "# Output: [[0,1,2,3,4,5,6,7,8,9], [3,4,5,6,7,8,9,10,11,12], ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a5cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_lines(transcript) -> str:\n",
    "    \"\"\"Join transcript entries into continuous text.\"\"\"\n",
    "    lines = []\n",
    "\n",
    "    for entry in transcript:\n",
    "        text = entry.text.replace('\\n', ' ')\n",
    "        lines.append(text)\n",
    "\n",
    "    return ' '.join(lines)\n",
    "\n",
    "def format_chunk(chunk):\n",
    "    \"\"\"Format a chunk with start/end timestamps and text.\"\"\"\n",
    "    time_start = format_timestamp(chunk[0].start)\n",
    "    time_end = format_timestamp(chunk[-1].start)\n",
    "    text = join_lines(chunk)\n",
    "\n",
    "    return {\n",
    "        'start': time_start,\n",
    "        'end': time_end,\n",
    "        'text': text\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70577b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 46 chunks\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "\n",
    "# Experiment with different values: try (30, 10) for more granular chunks\n",
    "for chunk in sliding_window(transcript, 60, 30):\n",
    "    processed = format_chunk(chunk)\n",
    "    chunks.append(processed)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaeb20d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': '52:34', 'end': '55:07', 'text': \"project I submitted was a fake course project. So there was nothing that's why I didn't get any points. Uh the reason I got uh nine uh is uh cuz I evaluated other peers. So that's why um like for each evalation I get three points. But this is how it's done. So the we evaluate projects by doing peer review and peer review is mandatory to complete the project. So if you submit a project but you don't do peer reviewing you fail the project and if you fail a project you fail the course. Right? So this very important to do peer reviews. Uh will the course make one job ready? Yes. If you put effort in the the the course and if you make a good project, if you also follow our recommendations to learn in public, this will definitely make you job ready. Uh what's the next path to follow after the completing the course? Uh to step into advanced stuff, find a job. That's the best way. Um cuz you can do courses forever, but I think you need to work on projects. This is where the real experience comes from. So you need to find something that is a job. Maybe at the beginning could be difficult but then find a volunteering job. I don't know there are so many places where you can volunteer. So put your skills into practice and then by doing this you will again do this project based learning that I um talked about and then it will force you to learn new things in order to solve a problem you have and then you build a portfolio of things and then it will make you even more job ready. Um yeah so I wouldn't recommend taking another course of course you can do a melops course that we have you can find a lot of courses like we have this page yeah wait no not this one 23 free online courses on machine learning so there are a lot of courses not just our course there are so many other courses but um I wouldn't recommend to spend too much time on learning things I would just say I mean on learning through courses. Courses are useful and important and for me personally courses were super helpful in my career but just don't do don't do just courses right so I would suggest to start involve being involved in different projects as soon as possible. Um you said the course videos are pre-recorded so the ones already available on the platform they will be\"}, {'start': '51:23', 'end': '53:52', 'text': \"sometimes you need to put something um but more often than not it's multiple choice questions. So you just uh do what we ask. So here this is how homeworks looks like. So you just need to install pandas and then we ask what is the version or uh you get some data and you need count records or uh do some exploratory data analysis in this particular case right and then you submit these things and because there is only one or two correct answers. This is graded automatically but we try to make this homeworks interesting enough so it's interesting for you and easier for us to grade. Right? So that's um when it comes to homeworks or uh midterm projects you need to evaluate u so you you deliver a project. So there are some criteria you need to satisfy. So these are the criteria problem description exploratory data analysis model training and so on. And then you also need to evaluate your peers and then at the end you get a report. So some Peters some of the peers they say um they give you feedback. So this is the feedback I got but the project I submitted was a fake course project. So there was nothing that's why I didn't get any points. Uh the reason I got uh nine uh is uh cuz I evaluated other peers. So that's why um like for each evalation I get three points. But this is how it's done. So the we evaluate projects by doing peer review and peer review is mandatory to complete the project. So if you submit a project but you don't do peer reviewing you fail the project and if you fail a project you fail the course. Right? So this very important to do peer reviews. Uh will the course make one job ready? Yes. If you put effort in the the the course and if you make a good project, if you also follow our recommendations to learn in public, this will definitely make you job ready. Uh what's the next path to follow after the completing the course? Uh to step into advanced stuff, find a job. That's the best way. Um cuz you can do courses forever, but I think you need to work on projects. This is where the real experience comes from. So you need to find something that is a job. Maybe at the beginning could be difficult but then find a volunteering job. I don't know there are so many\"}, {'start': '1:21', 'end': '3:49', 'text': \"thing. So we can also go to SLO and use ML Zoom camp and I'm going to use that for answering questions. Uh one thing though, so before we start, I just wanted to mention that um this course has been running for uh this will be the fifth edition of this course. So we've been doing this course for quite some time. Many people already graduated from this course and um most of the content we use here is the content I uh recorded like four years ago but we are updating the content so cuz u back then everyone was using Python 3.8 eight or nine something like. So yeah, we are re-recording some of the things in particular. Module one, two, three, four will uh stay the same cuz uh this uh these are the fundamentals. They didn't change. But module five we uh will update. Module 6 will stay the same. Module 8 we will update. Module 9 update update. And this we will not include like we only include it once and this thing get outdated very fast. So we just I just didn't bother updating this at all and it's pretty advanced material. So we will update like four out of 10 modules. So that's the plan. Uh and we already had some workshops for this. Anyways um you have some questions and these questions you use slido for asking these questions and let's get started. Um Alexi question is there a chance of job placement after the program? How deep are we going into computer vision and rock? Okay, so there are three questions actually here. Uh chance of job placement. So we do not provide you job placement. So we are not recruiters. We just teach this uh and we are not a boot camp where you pay money. Right? So this is a free boot camp and our resources are limited. So we cannot really uh do this for you. That said, many of many course participants who took this course in the past successfully found the job. So this is this is going to be the fifth time we are hosting this. So yeah, many many people have graduated from this course and many people found the jobs. So yes, there is a high chance to find a job placement after the program because the teach we the skills we teach here the skills we cover here they are the most important skills for a machine learning engineer. So first we focus on the machine learning part where\"}, {'start': '2:41', 'end': '5:10', 'text': \"this. Anyways um you have some questions and these questions you use slido for asking these questions and let's get started. Um Alexi question is there a chance of job placement after the program? How deep are we going into computer vision and rock? Okay, so there are three questions actually here. Uh chance of job placement. So we do not provide you job placement. So we are not recruiters. We just teach this uh and we are not a boot camp where you pay money. Right? So this is a free boot camp and our resources are limited. So we cannot really uh do this for you. That said, many of many course participants who took this course in the past successfully found the job. So this is this is going to be the fifth time we are hosting this. So yeah, many many people have graduated from this course and many people found the jobs. So yes, there is a high chance to find a job placement after the program because the teach we the skills we teach here the skills we cover here they are the most important skills for a machine learning engineer. So first we focus on the machine learning part where we cover scikitlearn um like simplest model models and then we go deeper on the deployment side. So this is the area where many data scientists um don't know or not they know but like maybe this is their weak areas. So this is we we're going a little deeper in this side. That's why it's more like an engineering program, ML engineering program. And with these skills, usually people don't have any problems finding a job. How deep are we going into computer vision and rack? Okay. So we don't go deep into computer vision. We have one module on deep learning and in this deep learning module we uh do we build an image classifier. So this is a model that can classify different types of clothes into images of of clothes into 10 different categories like pants, like shirts, like t-shirts, stuff like that. So this is as uh deep as we go to computer vision. So that's only one module about that. And we also talk about deploying neural networks. So in the serverless model we talked about how okay you have a model how to deploy it and by the way speaking of the deep learning model uh previously we used tensorflow so we are going to\"}, {'start': '33:18', 'end': '36:03', 'text': \"then you interact with others in Slack. Uh, yeah, I think I just answered that. Is it best to use a Kaggle data set or to find one ourselves? Is it a question about the project? Um, like Kaggle is a good platform for data sets, but it's not the only source. You can find data sets in other places too. So, It doesn't matter actually. I answered that question. Would you do a data science to camp? No. Uh I mean this one is kind of data scienceish cuz uh if we look at the syllabus, we have uh one, two, three, four, five, six modules. Did I correctly? One, two, three, four, five, six. Yeah, six modules or seven uh that are about data science. I think that's enough. Yeah, I don't see a point in creating another course just for that. So, it will be like the same material. Uh will we will we deploy ML models locally or use remote environment both? Um actually for the course uh for the project of the course you will get extra point if you deploy to the cloud uh but also I know some of you cannot um for whatever reasons um do the cloud thing then you can just deploy locally you will just get fewer points but we do show how to deploy to the cloud not just locally. I am a data engineer and I want to become a male engineer. Will this course help? If yes, how much? Yes, it will. Um, I don't know how to answer the second like very much. Yeah, well, it will help you. Yeah. Um, what is the better job for the future? Data engineer, data scientist or how do you measure better like um um the way I would rephrase it, what is the better job for me in the future? Do I enjoy doing data engineering, data science or machine learning? So once you have the answer then you have the answer for this question cuz the the point is to do what you enjoy most like if let's say somebody says oh yeah data engineers are more in more demand cuz there are more vacancies but then you hate data engineering you don't like it like so does it mean you have to do it or maybe there are fewer ML engineering jobs but you just like it more so then just go with this so yeah and then who knows maybe AI will\"}]\n"
     ]
    }
   ],
   "source": [
    "from minsearch import Index\n",
    "\n",
    "index = Index(text_fields=[\"text\"])\n",
    "index.fit(chunks)\n",
    "\n",
    "# Test search:\n",
    "results = index.search('Can I find a job after the course?', num_results=5)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bff8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can find a job after the course. Many participants from previous editions of the course have successfully found jobs after graduating. The course is designed to equip you with essential skills for becoming job-ready in machine learning. However, it is important to put in the effort during the course and to engage in practical projects, as real experience is crucial for job readiness. Additionally, getting involved in volunteer opportunities can also help you build a portfolio. \n",
      "\n",
      "For more details, you can refer to the video at the following timestamps:\n",
      "- Timestamp 1:21-3:49\n",
      "- Timestamp 51:23-55:07\n",
      "- Timestamp 56:18-58:55\n",
      "\n",
      "Here is the link to the video: https://www.youtube.com/watch?v=ph1PxZIkz1o\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def search(query):\n",
    "    \"\"\"Search for relevant documents.\"\"\"\n",
    "    return index.search(\n",
    "        query=query,\n",
    "        num_results=15\n",
    "    )\n",
    "\n",
    "instructions = \"\"\"\n",
    "Answer the QUESTION based on the CONTEXT from the subtitles of a YouTube video.\n",
    "\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "When answering the question, \n",
    "provide the citation in form of the video URL pointing at the timestamp where\n",
    "this is discussed. If the question is discussed in multiple documents,\n",
    "cite all of them.\n",
    "\n",
    "Don't use markdown or any formatting in the output.\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<VIDEO_ID>\n",
    "{video_id}\n",
    "</VIDEO_ID>\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(question, search_results):\n",
    "    context = json.dumps(search_results)\n",
    "    return prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        video_id=video_id\n",
    "    ).strip()\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    response = llm(prompt, instructions=instructions)\n",
    "    return response\n",
    "\n",
    "# Test it:\n",
    "answer = rag('Can I find a job after the course?')\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e453968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(user_prompt, instructions=None, model=\"gpt-4o-mini\"):\n",
    "    messages = []\n",
    "\n",
    "    if instructions:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": instructions\n",
    "        })\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt\n",
    "    })\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        input=messages\n",
    "    )\n",
    "\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c6157d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dda739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db313365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I just discovered the course, can I still join?',\n",
       " 'I just found out about this program. Can I still enroll?',\n",
       " 'you can join the course any time.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d8d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7f36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2acdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.99999976)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff52f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(948, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e2960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364c7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c051d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16707759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f593dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de464eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e0e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
