{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c8c19-3e34-46ce-9311-3fe618c5b19b",
   "metadata": {},
   "outputs": [],
   "source": "# OpenAI API Setup and Testing\n\nfrom openai import OpenAI"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed514a5-deb4-4bcd-812d-51bdda380682",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda94553-34d8-4322-ad42-7267e775b28a",
   "metadata": {},
   "outputs": [],
   "source": "## Example 1: Bedtime Story Assistant with System Prompts\n\ninstructions = \"\"\"\nYou're an assistant that creates bedtime stories. Include emojis in your responses.\nAsk the user follow up questions and make sure the stories are personalized to the user.\"\"\"\n\nmessages = [\n    {\"role\": \"system\", \"content\": instructions},\n    {\"role\": \"user\", \"content\": \"unicorn\"},\n]"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c78650-99f6-4248-be09-92bf622fc278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a magical choice! ðŸ¦„ Do you have a name for your unicorn, or would you like me to give it one? Also, where should our story take placeâ€”like a enchanted forest, a sparkling castle, or maybe somewhere else? ðŸŒˆâœ¨\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c36d05-47d1-45ca-bdbe-8bee10d0d959",
   "metadata": {},
   "outputs": [],
   "source": "# Continue the conversation by adding user's preferences\nanswer = \"1. green, 2. forest, 3. mega horn\"\nmessages.append({\"role\": \"user\", \"content\": answer})"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b0efc",
   "metadata": {},
   "outputs": [],
   "source": "# Inspect the conversation history\nmessages"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d73ae",
   "metadata": {},
   "outputs": [],
   "source": "# Generate the personalized bedtime story\nresponse = client.responses.create(\n    model=\"gpt-4o-mini\",\n    input=messages,\n)\n\nprint(response.output_text)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722477b2",
   "metadata": {},
   "outputs": [],
   "source": "## Inspecting the Response Object\n\n# The response object contains detailed metadata about the API call\nprint(response.model_dump_json(indent=2))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46b08a",
   "metadata": {},
   "outputs": [],
   "source": "# Accessing just the text output from the response\nresponse.output[0].content[0].text"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6335d4b",
   "metadata": {},
   "outputs": [],
   "source": "## Streaming Responses\n\n# Stream the response for real-time output\nstream = client.responses.create(\n    model=\"gpt-4o-mini\",\n    input=messages,\n    stream=True\n)\n\nfor event in stream:\n    if hasattr(event, 'delta'):\n        print(event.delta, end='')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79631622",
   "metadata": {},
   "outputs": [],
   "source": "## Using toyaikit for Interactive Chat\n\n!uv add toyaikit"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57a7b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.llm import OpenAIClient\n",
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.chat.runners import OpenAIResponsesRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855ad5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = OpenAIClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "972e0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = OpenAIResponsesRunner(\n",
    "    tools=None,\n",
    "    developer_prompt=instructions,\n",
    "    chat_interface=IPythonChatInterface(),\n",
    "    llm_client=llm_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ad44f",
   "metadata": {},
   "outputs": [],
   "source": "# Run the interactive chat interface\nrunner.run();"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0d82f",
   "metadata": {},
   "outputs": [],
   "source": "## Example 2: Personalized Joke Assistant\n\nsystem_prompt = \"\"\"\nYou're an assistant that can make jokes. Always find out the name of the person to make the joke personalized.\nOnce you know the name, make the joke about them.\n\"\"\".strip()\n\nmessages = [\n    {\"role\": \"system\", \"content\": system_prompt},\n    {\"role\": \"user\", \"content\": \"tell me a joke\"},\n]"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}